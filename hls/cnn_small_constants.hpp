#ifndef CNN_SMALL_CONSTANTS_HPP
#define CNN_SMALL_CONSTANTS_HPP

#define FLAT_SIZE(shape) (shape.batch_size * shape.channels * shape.n * shape.m)

/*
Same order as pytorch uses: [batch_size, channels, n, m]
*/
typedef struct image_shape {
    int batch_size;
    int channels;
    int n;
    int m;
} image_shape;

// Input image
const int batch_size = 1; // Only one image at a time, since this matches the SME implementation.
const image_shape input_shape = {batch_size, 1, 28, 28};

// Convolutional layer 1
const image_shape conv1_shape = {batch_size, 3, 26, 26};
const int conv1_k = 3;
//const int conv1_w_size = conv1_k * conv1_k * input_shape.channels * conv1_shape.channels;
const float conv1_w[3 * 3 * 1 * 3] = {
    -0.17628630995750427, -0.13457851111888885, 0.2742553949356079,
    -0.33332452178001404, 0.306591272354126, 0.3450981080532074,
    0.14231377840042114, -0.20551826059818268, 0.09386859834194183,
    -0.03430915251374245, -0.3332092761993408, -0.21485580503940582,
    0.061504412442445755, 0.20863422751426697, 0.10805066674947739,
    0.10353164374828339, 0.13175784051418304, 0.17544789612293243,
    0.20004460215568542, 0.2602260708808899, 0.006030739285051823,
    -0.3340633511543274, -0.29001420736312866, -0.1794050931930542,
    0.1354600191116333, -0.07904854416847229, 0.16741487383842468
};

// const int conv1_bias_size = conv1_shape.channels;
// const int conv1_bias_size = conv1_shape.channels;
const float conv1_bias[3] = {
    0.31626051664352417, -0.26537808775901794, 0.1493488848209381
};

// Batch normalization layer 1
const image_shape batchnorm1_shape = {batch_size, 3, 26, 26};
const float batchnorm1_means[3] = {
    0.36052051186561584, -0.23619629442691803, 0.13358604907989502
};
const float batchnorm1_vars[3] = {
    0.03489356487989426, 0.02087334357202053, 0.010060370899736881
};
const float batchnorm1_gammas[3] = {
    1.0154627561569214, 1.0381227731704712, 0.9544557929039001
};
const float batchnorm1_betas[3] = {
    -0.007384154014289379, -0.005790943279862404, 0.002264766488224268
};
const float batchnorm1_denoms[3] = {
    1 / std::sqrt(batchnorm1_vars[0] + 1e-5f),
    1 / std::sqrt(batchnorm1_vars[1] + 1e-5f),
    1 / std::sqrt(batchnorm1_vars[2] + 1e-5f)
};

// Relu layer 1
const image_shape relu1_shape = {batch_size, 3, 26, 26};

// Maxpool layer 1
const image_shape maxpool1_shape = {batch_size, 3, 13, 13};
const int maxpool1_k = 2;

// Convolutional layer 2
const image_shape conv2_shape = {batch_size, 5, 9, 9};
const int conv2_k = 5;
//const int conv2_w_size = conv2_k * conv2_k * maxpool1_shape.channels * conv2_shape.channels;
const float conv2_w[5 * 5 * 3 * 5] = {
    -0.04485854506492615, 0.039975062012672424, 0.058035023510456085,
    -0.06309245526790619, -0.1018887311220169, -0.025916414335370064,
    0.009901836514472961, 0.04351765289902687, 0.06260067969560623,
    -0.05420927703380585, -0.06558821350336075, 0.07455744594335556,
    0.14062030613422394, -0.0774751827120781, 0.12924593687057495,
    0.007953806780278683, 0.048304297029972076, 0.048660121858119965,
    -0.08228789269924164, -0.02375219576060772, -6.975431460887194e-05,
    -0.03302590548992157, 0.13297152519226074, 0.002770833671092987,
    -0.01953515037894249, -0.053181134164333344, -0.09313400089740753,
    -0.06788593530654907, 0.060341622680425644, -0.08875661343336105,
    -0.11812306195497513, -0.032547660171985626, -0.08270370960235596,
    0.1073710024356842, 0.07417742162942886, -0.03027360327541828,
    -0.0520167239010334, 0.06584248691797256, 0.028463201597332954,
    0.026924343779683113, 0.06906972080469131, 0.12791959941387177,
    -0.032998647540807724, 0.007054092828184366, -0.04168977960944176,
    0.0904870554804802, 0.010830865241587162, 0.019193345680832863,
    -0.039436183869838715, -0.07535858452320099, -0.01158436480909586,
    0.0325598269701004, -0.0022780781146138906, 0.0158439539372921,
    0.13116124272346497, -0.0738401859998703, -0.05579632520675659,
    -0.011778189800679684, -0.00631422596052289, 0.011828148737549782,
    -0.007452619262039661, 0.034776490181684494, -0.10390465706586838,
    0.0027617893647402525, 0.021924257278442383, 0.02706645429134369,
    0.0905359610915184, -0.09734166413545609, -0.06285350024700165,
    -0.09103594720363617, 0.10485401749610901, 0.05187853425741196,
    0.01630835421383381, -0.09243369847536087, 0.07104922831058502,
    -0.010084434412419796, -0.12641988694667816, 0.046815354377031326,
    0.11307287216186523, -0.04525166377425194, -0.03766811639070511,
    -0.01354142650961876, 0.018697431311011314, -0.01697622239589691,
    0.1667720377445221, -0.03124578855931759, 0.0936632826924324,
    0.07942662388086319, -0.06913211196660995, -0.12285400927066803,
    -0.00673658074811101, -0.03861454501748085, -0.013867337256669998,
    -0.11473093926906586, -0.10054367035627365, 0.015759440138936043,
    0.05204843729734421, -0.008130294270813465, -0.09734757989645004,
    -0.029965441673994064, 0.05168543756008148, -0.1806725412607193,
    0.004578903783112764, 0.16769693791866302, 0.23899607360363007,
    -0.053398486226797104, -0.054555971175432205, 0.04330555349588394,
    0.06954511255025864, -0.00652061402797699, -0.008581633679568768,
    0.0755215734243393, -0.009196201339364052, -0.05078405141830444,
    -0.040410418063402176, -0.05227817967534065, 0.03167480230331421,
    -0.07239815592765808, 0.10581954568624496, 0.10304457694292068,
    0.038427695631980896, -0.01499271485954523, -0.014650563709437847,
    0.11983201652765274, -0.008964885026216507, -0.00602147588506341,
    -0.08187541365623474, 0.15462082624435425, 0.05622154474258423,
    -0.016727985814213753, -0.004951521288603544, -0.026750735938549042,
    -0.01716216653585434, 0.01747303269803524, 0.12867790460586548,
    -0.019133858382701874, 0.02747298590838909, -0.08786969631910324,
    0.016857774928212166, 0.003466385882347822, 0.029956649988889694,
    0.022239401936531067, 0.019997434690594673, -0.02540595643222332,
    0.0040434664115309715, 0.05540104955434799, 0.008780463598668575,
    0.011944578029215336, 0.053233906626701355, 0.0599643737077713,
    -0.029293546453118324, 0.0016919750487431884, -0.01754097454249859,
    -0.07743337750434875, -0.008969019167125225, -0.037736691534519196,
    0.016687244176864624, -0.0930936336517334, -0.06021266430616379,
    -0.016982538625597954, 0.011608150787651539, -0.17583902180194855,
    0.009115160442888737, 0.08239773660898209, 0.08380583673715591,
    -0.05857427790760994, 0.10972964018583298, 0.13357552886009216,
    0.015038356184959412, -0.024518432095646858, -0.021252984181046486,
    0.028154250234365463, 0.0005095298402011395, 0.030956167727708817,
    -0.024293527007102966, 0.1599849909543991, -0.01578754186630249,
    0.11266554147005081, -0.006470317021012306, 0.003887468483299017,
    0.16605181992053986, -0.09352341294288635, 0.024849388748407364,
    -0.07762310653924942, 0.014891122467815876, 0.0018925488693639636,
    0.16514210402965546, 0.12942589819431305, -0.015429895371198654,
    -0.02861614152789116, 0.06742829829454422, 0.018118474632501602,
    0.0663357600569725, -0.025317475199699402, 0.08371172845363617,
    0.006950452458113432, -0.07840147614479065, -0.09553423523902893,
    -0.004353335127234459, 0.23809458315372467, 0.08221837133169174,
    0.03941743075847626, 0.07122177630662918, 0.0055521768517792225,
    -0.038775697350502014, -0.003921095281839371, 0.009698494337499142,
    -0.03329392522573471, 0.046266596764326096, 0.017358284443616867,
    -0.047650717198848724, -0.062130771577358246, 0.062360066920518875,
    0.17653079330921173, 0.093549944460392, 0.040579501539468765,
    0.017159616574645042, 0.009922214783728123, 0.028965767472982407,
    0.13946521282196045, -0.07191144675016403, -0.04821348562836647,
    0.06794905662536621, -0.026865096762776375, 0.05351974815130234,
    -0.08381003886461258, -0.06098904460668564, -0.07918499410152435,
    0.0883321687579155, 0.05545160174369812, 0.04861457645893097,
    -0.09333043545484543, 0.004091047681868076, 0.07446573674678802,
    0.07276580482721329, -0.024818897247314453, 0.022229164838790894,
    0.041448794305324554, 0.03310659900307655, -0.05203234404325485,
    -0.014516560360789299, 0.04546738043427467, -0.06423652917146683,
    -0.022996658459305763, -0.07366736233234406, -0.05036816745996475,
    0.018088677898049355, 0.00671442411839962, 0.05056990683078766,
    -0.1927000731229782, -0.07445574551820755, -0.03891654685139656,
    -0.029752230271697044, -0.007642179261893034, 0.09616322815418243,
    0.00541502283886075, -0.06371152400970459, 0.026496274396777153,
    0.12485477328300476, 0.08284790813922882, 0.0018851043423637748,
    0.009340617805719376, -0.03417080640792847, 0.05045486241579056,
    -0.08952555805444717, 0.07567816227674484, 0.02879573032259941,
    -0.014564195647835732, 0.034337807446718216, -0.0105088846758008,
    0.14985370635986328, 0.023553986102342606, -0.021357817575335503,
    -0.07945258915424347, -0.11622239649295807, -0.0004031138669233769,
    -0.04808437079191208, -0.11527543514966965, -0.019190657883882523,
    0.11169608682394028, -0.008611457422375679, -0.06286972761154175,
    -0.05079324170947075, 0.01611446589231491, -0.009668052196502686,
    -0.012635176070034504, -0.021467603743076324, 0.024431956931948662,
    -0.03581906110048294, -0.007793477736413479, -0.01501691434532404,
    0.04878123104572296, 0.05814123898744583, -0.093175008893013,
    0.06508533656597137, 0.049650222063064575, -0.05904775485396385,
    -0.03357502073049545, -0.020851079374551773, -0.10600496828556061,
    0.12804915010929108, 0.001461929059587419, -0.07640799880027771,
    -0.07629986107349396, -0.03932243213057518, 0.021252678707242012,
    0.07492366433143616, -0.038843121379613876, -0.015531125478446484,
    -0.05216631665825844, -0.12765035033226013, 0.17241111397743225,
    -0.16452054679393768, -0.024315783753991127, -0.001451251795515418,
    -0.036371201276779175, 0.10429602861404419, -0.03977273777127266,
    0.011696875095367432, -0.05683369189500809, 0.003226113971322775,
    0.14813971519470215, -0.07765398174524307, -0.0033715597819536924,
    0.04405084252357483, -0.0013353907270357013, 0.08924330025911331,
    -0.010639079846441746, -0.05456837639212608, 0.05471822991967201,
    -0.10528016835451126, -0.02631435915827751, 0.006971417460590601,
    -0.04819419980049133, 0.023633232340216637, -0.06645884364843369,
    -0.13998408615589142, 0.004429069347679615, 0.06799071282148361,
    -0.0015353907365351915, -0.004576359875500202, -0.03262875974178314,
    -0.033053863793611526, 0.13190357387065887, -0.0006120501202531159,
    0.0010195948416367173, -0.018881626427173615, 0.006434228271245956,
    0.13727959990501404, 0.021750889718532562, -0.009906316176056862,
    0.02043037861585617, 0.08289530873298645, -0.12202960252761841,
    -0.11674495041370392, 0.03324245661497116, 0.027817612513899803,
    -0.15222914516925812, -0.0957246944308281, -0.11108048260211945,
    0.01850849948823452, 0.09968843311071396, -0.0980135053396225,
    -0.07644756883382797, 0.0045596458949148655, 0.05074356123805046,
    0.048391055315732956, -0.0077959029003977776, -0.0685814693570137,
    -0.023064851760864258, -0.015124183148145676, 0.14451299607753754,
    0.05966012552380562, 0.04522571712732315, -0.06136468052864075
};

// const int conv2_bias_size = conv2_shape.channels;
const float conv2_bias[5] = {
    -0.08850874751806259, -0.11098580807447433, 0.030815714970231056,
    0.07129281014204025, 0.03910800442099571
};

// Batch Normalization layer 2
const image_shape batchnorm2_shape = { batch_size, 5, 9, 9 };
const float batchnorm2_means[5] = {
    0.001691692043095827, 0.20957469940185547, 0.7531698942184448,
    -0.11598194390535355, -0.2380867600440979
};
const float batchnorm2_vars[5] = {
    0.7013558745384216, 1.0189189910888672, 0.5014127492904663,
    0.7555098533630371, 0.515636146068573
};
const float batchnorm2_gammas[5] = {
    1.5110524892807007, 1.4778906106948853, 1.4420918226242065,
    1.313030481338501, 1.5031393766403198
};
const float batchnorm2_betas[5] = {
    0.0236506424844265, 0.02725145034492016, -0.013462454080581665,
    0.048654135316610336, 0.05783114209771156
};
const float batchnorm2_denoms[5] = {
    1 / std::sqrt(batchnorm2_vars[0] + 1e-5f),
    1 / std::sqrt(batchnorm2_vars[1] + 1e-5f),
    1 / std::sqrt(batchnorm2_vars[2] + 1e-5f),
    1 / std::sqrt(batchnorm2_vars[3] + 1e-5f),
    1 / std::sqrt(batchnorm2_vars[4] + 1e-5f)
};

// Relu layer 2
const image_shape relu2_shape = { batch_size, 5, 9, 9 };

#endif